# -*- coding: utf-8 -*-
"""Thesis work.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FSpKAo5k6DqkHmE28AxDxY5OnJb2V4OS
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
import os
from tqdm import tqdm
import cv2 as cv
from PIL import Image

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

# Commented out IPython magic to ensure Python compatibility.
# %cd D:\Manu sir\Malaria\processed_data\

un="Uninfected"
print("no of uninfected images : ",len(os.listdir(un)))

para="Parasitized"
print("No parasitized images : ",len(os.listdir(para)))

for image in tqdm(os.listdir(un)):
    if image!="Thumbs.db":
        img=cv.imread(os.path.join(un,image))
        print(img.shape)
        break

unin=[]
for image in tqdm(os.listdir(un)):
    if image!="Thumbs.db":
        img=Image.open(os.path.join(un,image))
        img=img.resize((64,64))
        img=np.asarray(img)
        unin.append(img)

print(len(unin))

print(len(unin[794]))
print(len(unin[7]))

par=[]
for image in tqdm(os.listdir(para)):
    if image!="Thumbs.db":
        img=Image.open(os.path.join(para,image))
        img=img.resize((64,64))
        img=np.asarray(img)
        par.append(img)

print(len(par))

ov_images=unin+par

print(len(ov_images))

labels=([0]*(len(os.listdir(un))-1))+([1]*(len(os.listdir(para))-1))

print(len(labels))

ov_images=np.array(ov_images)

type(ov_images)

labels=np.array(labels)

labels

type(labels)

ov_images=ov_images/255

from sklearn.utils import shuffle

ov_images,labels=shuffle(ov_images,labels)

labels[924]

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(ov_images,labels,test_size=0.2)

print(x_train.shape,y_train.shape)

print(x_test.shape,y_test.shape)

import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten
from keras import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping

model = Sequential(name="Custom_Xception")

#model.name="Custom_ResNet50"
model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=(64,64,3),activation='relu',padding="same"))
model.add(MaxPooling2D(pool_size=(2,2),strides=2))
model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(64,64,3),activation='relu',padding="same"))
model.add(MaxPooling2D(pool_size=(2,2),strides=2))
model.add(Conv2D(filters=128, kernel_size=(3,3),input_shape=(64,64,3),activation='relu',padding="same"))
model.add(MaxPooling2D(pool_size=(2,2),strides=2))
model.add(Conv2D(filters=256, kernel_size=(3,3),input_shape=(64,64,3),activation='relu',padding="same"))
model.add(MaxPooling2D(pool_size=(2,2),strides=2))

model.add(Flatten())

model.add(Dense(128,activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(50,activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(1,activation='softmax'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=["accuracy"])

model.summary()

history=model.fit(x_train,y_train,verbose=1,epochs=1,validation_data=(x_test,y_test), shuffle=True)

yhat=model.predict(x_test)>0.5

from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix,f1_score

precision_score(y_test,yhat)

f1_score(y_test,yhat)

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import confusion_matrix
cf_matrix=confusion_matrix(yhat,y_test)
print(cf_matrix)
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Purples')

